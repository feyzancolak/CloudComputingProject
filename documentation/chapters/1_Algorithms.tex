\chapter{Algorithms}


The goal of the project is to explore the core algorithms implemented for analyzing letter frequency across different languages using Hadoop MapReduce. 
The project focuses on processing text documents to extract insights into the occurrence of standard alphabet characters within specific languages, namely Italian, English, and Turkish. 
To be able to distinguish the different alphabets, a class languageNormalizer was implemented. \\\\
Furthermore, the input texts also have different dimensions, ranging from small to large datasets.
In this way we can test the performance of the algorithms with different input sizes. \\
The project has two types of implementations: Combiner and InMapper. Both techniques share the goal of improving MapReduce efficiency by reducing network traffic and enhancing processing speed through partial aggregation. They also both use the partitioner functionality, which provides an even distribution of data among the reducers, rather than a random distribution. However, they differ in execution stage and scope: the Combiner aggregates data after Mapper tasks and before Reducers, while the InMapper integrates aggregation within each Mapper task, thereby potentially minimizing resource overhead and optimizing memory usage. \\
The execution of the classes is managed by the RunProcess utility, which orchestrates the input file processing, language selection, output path management, and configurable parameters such as the number of Reducers employed. The input file is first used by the letterCount class to count the number of letters in the text. This information is stored in a temporary file, which is taken as input from the letterFrequency class that then calculates the frequency of each letter in the text. The output of the letterFrequency class is the final result of the analysis, and to this it is also added the result of the letterCount.

\section{Combiner}

The Combiner acts as a mini-reducer that performs local aggregation of intermediate data before it is sent to the reducers. By summing up the counts of each character within the Mapper tasks, the Combiner reduces the volume of data transferred across the network, which significantly enhances the efficiency of the MapReduce job. This local aggregation minimizes the amount of data that needs to be shuffled, sorted, and processed by the Reducer tasks, thereby optimizing the overall performance of the letter frequency analysis.


    

\subsection{LetterCount}
The LetterCount algorithm is implemented using Hadoop's MapReduce framework to count occurrences of standard alphabet characters within text documents.

\begin{algorithm}
    \caption{LetterCount with Combiner}
    \begin{algorithmic}[1]
    \Require Txt file
    \Ensure Total number of characters belonging to the specified language alphabet
    \\
    \Statex
    
    \textbf{Class:} MAPPERCOUNTER
    \State \textbf{initialize:}
    \State  characterCounts: Map<String, Long> \\
    
    \Procedure{setup}{$context$}
        \State Initialize characterCounts as an empty map
    \EndProcedure\\
    
    \Procedure{map}{$key, value, context$}
        \State $\text{line} \gets \text{LanguageNormalizer.normalize}(value.toString().toLowerCase(), language)$
        \For{each character $ch$ in $line$}
                \State $\text{charStr} \gets \text{String.valueOf}(ch)$
                \State $\text{Emit}(\text{character}, \text{one})$
        \EndFor
    \EndProcedure\\
        
    \Statex
    
    \textbf{Class:} REDUCERCOUNTER
    \Procedure{reduce}{$key, values, context$}
        \State $\text{sum} \gets 0$
        \For{each $\text{value}$ in $values$}
            \State $\text{sum} \gets \text{sum} + \text{value}$
        \EndFor
        \State $\text{Emit}(\text{key}, \text{sum})$
    \EndProcedure
    \end{algorithmic}
    \end{algorithm}

\textbf{Mapper Class (MapperCounter)}
\begin{longtable}{|>{\raggedright\arraybackslash}p{0.3\textwidth}|>{\raggedright\arraybackslash}p{0.65\textwidth}|}
    \hline
    Setup &  Initializes the character count map and regex pattern.\\
    \hline
    Map &  Processes each line, normalizes it, and counts the occurrences of each letter.\\
    \hline
    Cleanup &Writes the accumulated character counts to the context.\\
    \hline
\end{longtable}



\textbf{Reducer Class (ReducerCounter)}
\begin{longtable}{|>{\raggedright\arraybackslash}p{0.3\textwidth}|>{\raggedright\arraybackslash}p{0.65\textwidth}|}
    \hline
    Reduce & Aggregates counts for each character from the mapper output and writes the total count to the context. \\
    \hline
\end{longtable}



\subsection{LetterFrequency}

The LetterFrequency algorithm calculates the frequency of standard alphabet characters within text documents using Hadoop's MapReduce framework.\\




\begin{algorithm}
    \caption{LetterFrequency with Combiner}
    \begin{algorithmic}[1]
    \Require Txt file
    \Ensure Frequency of each character belonging to the specified language alphabet
    \\
    \Statex
    
    \textbf{Class:} MAPPERFREQUENCY
    \State \textbf{initialize:}
    \State  reducerKey: Text
    \State  reducerValue: LongWritable(1) \\
    
    \Procedure{setup}{$context$}

    \EndProcedure\\
    
    \Procedure{map}{$key, value, context$}
        \State $\text{line} \gets \text{LanguageNormalizer.normalize}(value.toString().toLowerCase(), language)$
        \For{each character $ch$ in $line$}
                \State $\text{charStr} \gets \text{String.valueOf}(ch)$
                \State $\text{Emit}(character, one)$
        \EndFor
    \EndProcedure\\
    
    \Statex
    
    \textbf{Class:} COMBINERFREQUENCY
    \Procedure{reduce}{$key, values, context$}
        \State \textbf{initialize:} sum as 0
        \For{each value in values}
            \State sum += value
        \EndFor
        \State $\text{Emit}(key, sum)$
    \EndProcedure\\
    
    \Statex
    
    \textbf{Class:} REDUCERFREQUENCY
    \Procedure{setup}{$context$}
        \State \text{TEXT\_LENGTH} = context.getConfiguration().getLong("totalLetterCount", 0)
    \EndProcedure\\
    
    \Procedure{reduce}{$key, values, context$}
        \State \textbf{initialize:} sum as 0
        \For{each value in values}
            \State sum += value
        \EndFor
        \State result = sum / TEXT\_LENGTH
        \State $\text{Emit}(key, result)$
    \EndProcedure
    
    \end{algorithmic}
    \end{algorithm}


\textbf{MapperFrequency}
\begin{longtable}{|>{\raggedright\arraybackslash}p{0.3\textwidth}|>{\raggedright\arraybackslash}p{0.65\textwidth}|}
    \hline
    Setup &   Initializes the character count map and regex pattern.\\
    \hline
    Map &  Processes each line, normalizes it, and counts the occurrences of each letter.\\
    \hline
    Cleanup & Writes the accumulated character counts to the context.\\
    \hline
\end{longtable}


\textbf{CombinerFrequency}
\begin{longtable}{|>{\raggedright\arraybackslash}p{0.3\textwidth}|>{\raggedright\arraybackslash}p{0.65\textwidth}|}
    \hline
    Reduce & Aggregates counts for each character from the mapper output and writes the intermediate sums to the context.\\
    \hline
\end{longtable}

\textbf{ReducerFrequency}
\begin{longtable}{|>{\raggedright\arraybackslash}p{0.3\textwidth}|>{\raggedright\arraybackslash}p{0.65\textwidth}|}
    \hline
    Setup & Retrieves the total letter count from the configuration. \\
    \hline
    Map & Calculates the frequency of each character by dividing the count by the total number of characters and writes the result to the context.\\
    \hline
\end{longtable}



\section{InMapper Combining}
The InMapper combining technique ensures efficiency by performing aggregation within each Mapper task itself. This approach reduces the amount of data shuffled across the network and further optimizes the processing of letter frequency analysis.


\subsection{LetterCount}

The LetterCount algorithm is implemented using Hadoop's MapReduce framework to count occurrences of standard alphabet characters within text documents. Here’s the algorithm overview:


\begin{algorithm}
\caption{LetterCount with In-Mapper Combining}

\begin{algorithmic}[1]
\Class{Mapper}{}
    \Procedure {Initialize}{}
    \State $\text{H} \gets$ new AssociativeArray \Comment{Initialize map for character counts}
    \State $\text{charPattern} \gets \text{compilePattern}("[a-zçğışöü]")$ \Comment{Include Turkish characters}
    \EndProcedure

    \Statex
    \Procedure{Map}{$\text{docid } key, \text{doc } value$}
    \State $\text{language} \gets \text{context.getConfiguration("language")}$ \Comment{Retrieve language}
    \State $\text{line} \gets \text{LanguageNormalizer.normalize(value.toString(), language)}$ \Comment{Normalize and convert}
     \For{$\text{each } \text{char } c \text{ in } \text{line}$}
        \If{$\text{charPattern.matches(String.valueOf(c))}$}
        \State $H[c] \gets H.getOrDefault(c, 0) + 1$ \Comment{Update character count}
        \EndIf
    \EndFor
    \EndProcedure
    \Statex
    \Procedure{Close}{}
    \For{$\text{each } \text{char } c \text{ in } H$}
        \State $\text{Emit}(c, \text{count } H[c])$ \Comment{Output character count}
    \EndFor
    \EndProcedure
\EndClass
\end{algorithmic}

\vspace{0.5cm}  % Add vertical space between classes

\begin{algorithmic}[1]
\Class{Partitioner}{}
  \Procedure{GetPartition}{$\text{char } key, \text{count } value, \text{numReducers }$}
    \State \textbf{return} $(\text{key.hashCode()} \& \text{Integer.MAX\_VALUE}) \% \text{numReducers}$
    \Comment{Default hash-based partitioning}
  \EndProcedure
\EndClass
\end{algorithmic}


\vspace{0.5cm}  % Add vertical space between classes


\begin{algorithmic}[1]
\Class{Reducer}{}
    \Procedure{Initialize}{}
    \State $\text{result} \gets 0$ \Comment{Initialize result}
    \EndProcedure

    \Statex
    \Procedure{Reduce}{$\text{char } key, \text{counts } values$}
    \State $\text{sum} \gets 0$
    \For{$\text{each } \text{count } \text{val} \text{ in } \text{values}$}
        \State $\text{sum} \gets \text{sum} + \text{val}$ \Comment{Sum counts for each character}
    \EndFor
    \State $\text{result} \gets \text{sum}$
    \State $\text{Emit}(key, \text{count } \text{result})$ \Comment{Output final count}
    \EndProcedure
\EndClass
\end{algorithmic}

\end{algorithm}




\subsection{LetterFrequency}
The LetterFrequency algorithm calculates the frequency of standard alphabet characters within text documents using Hadoop's MapReduce framework.














